{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ba1d6d1-f8e0-46c3-bfc0-7e75dab80e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f0599a2c-dfff-4e3f-810b-4867afd070c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_2d(inp, oup, kernel_size=3, stride=1, groups=1, bias=False, norm=True, act=True):\n",
    "    conv = nn.Sequential()\n",
    "    padding = (kernel_size - 1) // 2\n",
    "    conv.add_module('conv', nn.Conv2d(inp, oup, kernel_size, stride, padding, bias=bias, groups=groups))\n",
    "    if norm:\n",
    "        conv.add_module('BatchNorm2d', nn.BatchNorm2d(oup))\n",
    "    if act:\n",
    "        conv.add_module('Activation', nn.ReLU6())\n",
    "    return conv\n",
    "\n",
    "class MultiQueryAttentionLayerWithDownSampling(nn.Module):\n",
    "    def __init__(self, inp, num_heads, key_dim, value_dim, query_h_strides, query_w_strides, kv_strides, dw_kernel_size=3, dropout=0.0):\n",
    "        \"\"\"Multi Query Attention with spatial downsampling.\n",
    "        Referenced from here https://github.com/tensorflow/models/blob/master/official/vision/modeling/layers/nn_blocks.py\n",
    "\n",
    "        3 parameters are introduced for the spatial downsampling:\n",
    "        1. kv_strides: downsampling factor on Key and Values only.\n",
    "        2. query_h_strides: vertical strides on Query only.\n",
    "        3. query_w_strides: horizontal strides on Query only.\n",
    "\n",
    "        This is an optimized version.\n",
    "        1. Projections in Attention is explict written out as 1x1 Conv2D.\n",
    "        2. Additional reshapes are introduced to bring a up to 3x speed up.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.value_dim = value_dim\n",
    "        self.query_h_strides = query_h_strides\n",
    "        self.query_w_strides = query_w_strides\n",
    "        self.kv_strides = kv_strides\n",
    "        self.dw_kernel_size = dw_kernel_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.head_dim = key_dim // num_heads\n",
    "\n",
    "        if self.query_h_strides > 1 or self.query_w_strides > 1:\n",
    "            self._query_downsampling_norm = nn.BatchNorm2d(inp)\n",
    "        self._query_proj = conv_2d(inp, num_heads*key_dim, 1, 1, norm=False, act=False)\n",
    "        \n",
    "        if self.kv_strides > 1:\n",
    "            self._key_dw_conv = conv_2d(inp, inp, dw_kernel_size, kv_strides, groups=inp, norm=True, act=False)\n",
    "            self._value_dw_conv = conv_2d(inp, inp, dw_kernel_size, kv_strides, groups=inp, norm=True, act=False)\n",
    "        self._key_proj = conv_2d(inp, key_dim, 1, 1, norm=False, act=False)\n",
    "        self._value_proj = conv_2d(inp, key_dim, 1, 1, norm=False, act=False)\n",
    "\n",
    "        if self.query_h_strides > 1 or self.query_w_strides > 1:\n",
    "            self._output_upsample = nn.Upsample(scale_factor=(self.query_h_strides, self.query_w_strides), mode='bilinear')\n",
    "        self._output_proj = conv_2d(num_heads*key_dim, inp, 1, 1, norm=False, act=False)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, _, _ = x.size()\n",
    "        if self.query_h_strides > 1 or self.query_w_strides > 1:\n",
    "            q = F.avg_pool2d(x,(self.query_h_stride, self.query_w_stride))\n",
    "            q = self._query_downsampling_norm(q)\n",
    "            q = self._query_proj(q)\n",
    "        else:\n",
    "            q = self._query_proj(x)\n",
    "        px = q.size(2)\n",
    "        q = q.view(batch_size, self.num_heads, -1, self.key_dim) # [batch_size, num_heads, seq_length, key_dim]\n",
    "\n",
    "        if self.kv_strides > 1:\n",
    "            k = self._key_dw_conv(x)\n",
    "            k = self._key_proj(k)\n",
    "            v = self._value_dw_conv(x)\n",
    "            v = self._value_proj(v)          \n",
    "        else:\n",
    "            k = self._key_proj(x)\n",
    "            v = self._value_proj(x)\n",
    "        k = k.view(batch_size, 1, self.key_dim, -1) # [batch_size, 1, key_dim, seq_length]\n",
    "        v = v.view(batch_size, 1, -1, self.key_dim) # [batch_size, 1, seq_length, key_dim]\n",
    "\n",
    "        # calculate attn score\n",
    "        attn_score = torch.matmul(q, k) / (self.head_dim ** 0.5)\n",
    "        attn_score = self.dropout(attn_score)\n",
    "        attn_score = F.softmax(attn_score, dim=-1)\n",
    "\n",
    "        context = torch.matmul(attn_score, v)\n",
    "        context = context.view(batch_size, self.num_heads * self.key_dim, px, px)\n",
    "        \n",
    "        output = self._output_upsample(context)\n",
    "        output = self._output_proj(context)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2343cf54-79ac-406b-9422-560fa43f756f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 15, 15])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = 3\n",
    "num_heads = 2\n",
    "key_dim = 8\n",
    "query_h_strides = 3\n",
    "query_w_strides = 3\n",
    "\n",
    "head_dim = key_dim // num_heads\n",
    "input_tensor = torch.randn((1,inp,15,15))\n",
    "batch_size, seq_length, _, _ = input_tensor.size()\n",
    "conv_2d(inp,7)(input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e45fad13-5dc9-4fbd-a0b1-ef7c91c692f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 5, 5])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_dw_conv = conv_2d(inp, inp, 3, (query_h_strides, query_w_strides), groups=inp, norm=True, act=False)\n",
    "query_proj = conv_2d(inp, num_heads*key_dim, 1, 1, norm=False, act=False)\n",
    "query_downsampling_norm = nn.BatchNorm2d(inp)\n",
    "q = F.avg_pool2d(input_tensor,(query_h_strides, query_w_strides))\n",
    "q = query_downsampling_norm(q)\n",
    "q = query_proj(q)\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3660dbe4-0fc7-4568-86b3-4e7098b076d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 25, 8])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px = q.size(2)\n",
    "q = q.view(batch_size, num_heads, -1, key_dim)\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "30bd3d31-0781-4247-a2d1-f24e3df1e166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 8, 8])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_dw_conv = conv_2d(inp, inp, 3, 2, groups=inp, norm=True, act=False)\n",
    "k = key_dw_conv(input_tensor)\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ae17d062-e602-44c3-815f-150f6339a7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 8, 8])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_proj = conv_2d(inp, key_dim, 1, 1, norm=False, act=False)\n",
    "k = key_proj(k)\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bf80d1af-288c-4d32-ae7d-3833a03b7742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 64])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = k.view(batch_size, 1, key_dim, -1)\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a40b71ab-3777-473f-a948-790610bb9c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 25, 64])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_score = torch.matmul(q, k) / (head_dim ** 0.5)\n",
    "attn_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dbf11b30-9a00-4aa2-98e6-bb9f095a052e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 25, 64])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_score = F.softmax(attn_score, dim=-1)\n",
    "attn_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "780e603d-1f25-425e-8c3b-43592a4b9e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 8])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = k.view(batch_size, 1, -1, key_dim)\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a8a408b0-37db-407b-9a5b-fd9a82809fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 25, 8])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = torch.matmul(attn_score, v)\n",
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2c4bb898-d454-42f6-937a-912635a8f9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 5, 5])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = context.view(batch_size, num_heads * key_dim, px, px)\n",
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8436bb1a-1e9e-4272-8ff6-951c56e247b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 15, 15])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_upsample = nn.Upsample(scale_factor=(query_h_strides, query_w_strides), mode='bilinear')\n",
    "output = output_upsample(context)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c481561a-923a-4e6d-9565-0bfb3ff186cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 15, 15])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_proj = conv_2d(num_heads*key_dim, inp, 1, 1, norm=False, act=False)\n",
    "output = output_proj(output)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f67ce9-6a9a-4c33-9358-c2b81ba91418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c62720a-6018-4972-98a8-badd3d8b82c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
