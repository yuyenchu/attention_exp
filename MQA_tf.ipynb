{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ead3d-cb5e-4bae-9573-1ec114375ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as tf_keras\n",
    "\n",
    "class OptimizedMultiQueryAttentionLayerWithDownSampling(tf_keras.layers.Layer):\n",
    "  \"\"\"Multi Query Attention with spatial downsampling.\n",
    "\n",
    "   3 parameters are introduced for the spatial downsampling:\n",
    "   1. kv_strides: downsampling factor on Key and Values only.\n",
    "   2. query_h_strides: vertical strides on Query only.\n",
    "   3. query_w_strides: horizontal strides on Query only.\n",
    "\n",
    "  This is an optimized version.\n",
    "  1. Projections in Attention is explict written out as 1x1 Conv2D.\n",
    "  2. Additional reshapes are introduced to bring a up to 3x speed up.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      num_heads: int,\n",
    "      key_dim: int,\n",
    "      value_dim: int,\n",
    "      query_h_strides: int = 1,\n",
    "      query_w_strides: int = 1,\n",
    "      kv_strides: int = 1,\n",
    "      dropout: float = 0,\n",
    "      dw_kernel_size: int = 3,\n",
    "      use_sync_bn: bool = False,\n",
    "      norm_momentum: float = 0.99,\n",
    "      norm_epsilon: float = 0.001,\n",
    "  ):\n",
    "    \"\"\"Initializer.\n",
    "\n",
    "    Args:\n",
    "      num_heads: Number of attention heads.\n",
    "      key_dim: Size of the attention key dimension.\n",
    "      value_dim: Size of the attention value dimension.\n",
    "      query_h_strides: Vertical stride size for query only.\n",
    "      query_w_strides: Horizontal stride size for query only.\n",
    "      kv_strides: Key and value stride size.\n",
    "      dropout: Dropout probability (between 0 and 1).\n",
    "      dw_kernel_size: Spatial dimension of the depthwise kernel.\n",
    "      use_sync_bn: If True, use synchronized batch normalization.\n",
    "      norm_momentum: Momentum value for use with normalization moving average.\n",
    "      norm_epsilon: Small float added to norm variance to avoid dividing by\n",
    "        zero.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self._num_heads = num_heads\n",
    "    self._key_dim = key_dim\n",
    "    self._value_dim = value_dim\n",
    "    self._query_h_strides = query_h_strides\n",
    "    self._query_w_strides = query_w_strides\n",
    "    self._kv_strides = kv_strides\n",
    "    self._dw_kernel_size = dw_kernel_size\n",
    "    self._dropout = dropout\n",
    "    self._norm_momentum = norm_momentum\n",
    "    self._norm_epsilon = norm_epsilon\n",
    "\n",
    "    if use_sync_bn:\n",
    "      self._norm = tf_keras.layers.experimental.SyncBatchNormalization\n",
    "    else:\n",
    "      self._norm = tf_keras.layers.BatchNormalization\n",
    "    if tf_keras.backend.image_data_format() == 'channels_last':\n",
    "      self._bn_axis = -1\n",
    "    else:\n",
    "      self._bn_axis = 1\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    \"\"\"Create layer state.\"\"\"\n",
    "    self._channel_dim = input_shape[-1]\n",
    "\n",
    "    if self._query_h_strides > 1 or self._query_w_strides > 1:\n",
    "      self._query_downsampling = tf_keras.layers.AvgPool2D(\n",
    "          pool_size=(self._query_h_strides, self._query_w_strides),\n",
    "          padding='same',\n",
    "      )\n",
    "      self._query_downsampling_norm = self._norm(\n",
    "          axis=self._bn_axis,\n",
    "          momentum=self._norm_momentum,\n",
    "          epsilon=self._norm_epsilon,\n",
    "      )\n",
    "\n",
    "    self._query_proj = tf_keras.layers.Conv2D(\n",
    "        filters=self._num_heads * self._key_dim,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='valid',\n",
    "        use_bias=False,\n",
    "    )\n",
    "\n",
    "    if self._kv_strides > 1:\n",
    "      self._key_dw_conv = tf_keras.layers.DepthwiseConv2D(\n",
    "          kernel_size=self._dw_kernel_size,\n",
    "          strides=self._kv_strides,\n",
    "          padding='same',\n",
    "          depth_multiplier=1,\n",
    "          use_bias=False,\n",
    "      )\n",
    "      self._key_dw_norm = self._norm(\n",
    "          axis=self._bn_axis,\n",
    "          momentum=self._norm_momentum,\n",
    "          epsilon=self._norm_epsilon,\n",
    "      )\n",
    "    self._key_proj = tf_keras.layers.Conv2D(\n",
    "        filters=self._key_dim,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        use_bias=False,\n",
    "    )\n",
    "\n",
    "    if self._kv_strides > 1:\n",
    "      self._value_dw_conv = tf_keras.layers.DepthwiseConv2D(\n",
    "          kernel_size=self._dw_kernel_size,\n",
    "          strides=self._kv_strides,\n",
    "          padding='same',\n",
    "          depth_multiplier=1,\n",
    "          use_bias=False,\n",
    "      )\n",
    "      self._value_dw_norm = self._norm(\n",
    "          axis=self._bn_axis,\n",
    "          momentum=self._norm_momentum,\n",
    "          epsilon=self._norm_epsilon,\n",
    "      )\n",
    "    self._value_proj = tf_keras.layers.Conv2D(\n",
    "        filters=self._value_dim,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        use_bias=False,\n",
    "    )\n",
    "\n",
    "    self._output_proj = tf_keras.layers.Conv2D(\n",
    "        filters=self._channel_dim,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='valid',\n",
    "        use_bias=False,\n",
    "    )\n",
    "    if self._query_h_strides > 1 or self._query_w_strides > 1:\n",
    "      self._upsampling = tf_keras.layers.UpSampling2D(\n",
    "          size=(self._query_h_strides, self._query_w_strides),\n",
    "          interpolation='bilinear',\n",
    "      )\n",
    "    self._dropout_layer = tf_keras.layers.Dropout(rate=self._dropout)\n",
    "\n",
    "  def _reshape_input(self, t):\n",
    "    \"\"\"Reshapes a tensor to three dimensions, keeping the first and last.\"\"\"\n",
    "    s = tf.shape(t)\n",
    "    # Propagate the shape statically where possible.\n",
    "    static_num = t.shape[1:-1].num_elements()\n",
    "    num = static_num or tf.math.reduce_prod(s[1:-1])\n",
    "    return tf.ensure_shape(\n",
    "        tf.reshape(t, [s[0], num, s[-1]]), [t.shape[0], static_num, t.shape[-1]]\n",
    "    )\n",
    "\n",
    "  def _reshape_projected_query(self, t, num_heads, h_px, w_px, key_dim):\n",
    "    \"\"\"Reshapes projected query: [b, n, n, h x k] -> [b, n x n, h, k].\"\"\"\n",
    "    s = tf.shape(t)\n",
    "    return tf.reshape(t, [s[0], h_px * w_px, num_heads, key_dim])\n",
    "\n",
    "  def _get_pixels(self, t):\n",
    "    s = tf.shape(t)\n",
    "    static_num = t.shape[1]\n",
    "    px = static_num or s[1]\n",
    "    return px\n",
    "\n",
    "  def _reshape_output(self, t, num_heads, h_px, w_px):\n",
    "    \"\"\"Reshape output:[b, n x n x h, k] -> [b, n, n, hk].\"\"\"\n",
    "    s = tf.shape(t)\n",
    "    # Propagate the shape statically where possible.\n",
    "    static_last_dim = t.shape[-1]\n",
    "    last_dim = (static_last_dim or s[-1]) * num_heads\n",
    "    return tf.reshape(t, [t.shape[0] or s[0], h_px, w_px, last_dim])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    \"\"\"Run layer computation.\"\"\"\n",
    "    x = inputs\n",
    "    px = self._get_pixels(x)\n",
    "\n",
    "    if self._query_h_strides > 1 or self._query_w_strides > 1:\n",
    "      q = self._query_downsampling(x)\n",
    "      q = self._query_downsampling_norm(q)\n",
    "      q = self._query_proj(q)\n",
    "    else:\n",
    "      q = self._query_proj(x)\n",
    "\n",
    "    # desired q shape: [b, n x n, h, k] - [b, l, h, k]\n",
    "    q = self._reshape_projected_query(\n",
    "        q,\n",
    "        self._num_heads,\n",
    "        px // self._query_h_strides,\n",
    "        px // self._query_w_strides,\n",
    "        self._key_dim,\n",
    "    )\n",
    "\n",
    "    if self._kv_strides > 1:\n",
    "      k = self._key_dw_conv(x)\n",
    "      k = self._key_dw_norm(k)\n",
    "      k = self._key_proj(k)\n",
    "    else:\n",
    "      k = self._key_proj(x)\n",
    "    # output shape of k: [b, k, p], p = m x m\n",
    "    k = self._reshape_input(k)\n",
    "\n",
    "    # desired q shape: [b, n x n, h, k]\n",
    "    # desired k shape: [b, m x m, k]\n",
    "    # desired logits shape: [b, n x n, h, m x m]\n",
    "    logits = tf.einsum('blhk,bpk->blhp', q, k)\n",
    "\n",
    "    logits = logits / tf.math.sqrt(tf.cast(self._key_dim, x.dtype))\n",
    "\n",
    "    attention_scores = self._dropout_layer(tf.nn.softmax(logits))\n",
    "\n",
    "    if self._kv_strides > 1:\n",
    "      v = self._value_dw_conv(x)\n",
    "      v = self._value_dw_norm(v)\n",
    "      v = self._value_proj(v)\n",
    "    else:\n",
    "      v = self._value_proj(x)\n",
    "\n",
    "    # output shape of v: [ b, p, k], p = m x m\n",
    "    v = self._reshape_input(v)\n",
    "    o = tf.einsum('blhp,bpk->blhk', attention_scores, v)\n",
    "    # reshape o into [b, n, n, hk]\n",
    "    o = self._reshape_output(\n",
    "        o,\n",
    "        self._num_heads,\n",
    "        px // self._query_h_strides,\n",
    "        px // self._query_w_strides,\n",
    "    )\n",
    "    if self._query_h_strides > 1 or self._query_w_strides > 1:\n",
    "      o = self._upsampling(o)\n",
    "\n",
    "    result = self._output_proj(o)\n",
    "\n",
    "    return tf.ensure_shape(tf.reshape(result, tf.shape(x)), x.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
